#!/bin/sh

##################################### Start of Script #########33##########################

################################### Select your cluster ###################################
###SBATCH --cluster=ub-hpc
#SBATCH --cluster=faculty

## Select your partition
#SBATCH --partition=scavenger --qos=scavenger

################################### Set your running time ###################################
#SBATCH --time=72:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=2

################################### Select your GPU ###################################
## Use snodes command to check their status first
###SBATCH --gres=gpu:tesla_v100-pcie-32gb:2
###SBATCH --gres=gpu:tesla_v100-pcie-16gb:2
###SBATCH --gres=gpu:a100-pcie-40gb:2
###SBATCH --gres=gpu:nvidia_a16:12


### just give my job a single gpu
#SBATCH --gres=gpu:1
### give me a node which has the A100 gpus in it
#â€‹SBATCH --constraint=A100 

################################### Set your memory ###################################
#SBATCH --mem=65536
# Memory per node specification is in MB. It is optional. 
# The default limit is 3000MB per core.

################################### Set your job name ###################################
#SBATCH --job-name="Auto_Tune_TTVO_S1"

## Set output name (not work very well right now)
### SBATCH --output= "result_$(date +"%Y_%m_%d_%k_%M_%S").out"

############################ Set the email to receive email #############################
#SBATCH --mail-user=shaoshus@buffalo.edu
#SBATCH --mail-type=ALL
##SBATCH --requeue
#Specifies that the job will be requeued after a node failure.
#The default is that the job will not be requeued.


################### Beginning of your scipt, it is written with shell ####################

echo "SLURM_JOBID="$SLURM_JOBID
echo "SLURM_TIME="$(date +"%Y_%m_%d_%k_%M_%S")

echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST
echo "SLURM_NNODES"=$SLURM_NNODES
echo "SLURMTMPDIR="$SLURMTMPDIR

echo "working directory = "$SLURM_SUBMIT_DIR


# module use /projects/academic/cwx/modulefiles
# module load python/my-python-3
source ~/.bashrc
conda activate shaoshu

## List the module your are using
module list
ulimit -s unlimited

which python
which pytest

nvidia-smi

cat optuna_strain_multicamvo.script

################################################Auto Tune Parameters############################################################

# data_dir=data/EuRoC_V102
# data_dir=/data/datasets/wenshanw/tartan_data
# data_dir=/data/tartanair
# data_dir=/home/data/tartanair/TartanAir_comb
data_dir=/user/shaoshus/projects/tartanair/TartanAir

# lr=1e-5
batch=32
step=100000

root_dir=train_multicamvo
# train_name=multicamvo_lr=${lr}_batch=${batch}_step=${step}_SepFeatEncoder
# train_name="test_4e-5_1000_tunetrans"
# train_name=all_frames
# continue_from=multicamvo_lr=1e-5_batch=32_step=100000_SepFeatEncoder_s=12500
# train_name = debug_autotuna_lr_batch=${batch}_step=${step}_10Scenes_s=29000

train_name=multicamvo_B${batch}_St${step}_optuna_lr


echo "train_name: ${train_name}"

# train
python optuna_train_multicamvo2.py \
    --flow-model-name ./models/pwc_net.pth.tar \
    --batch-size ${batch} \
    --worker-num 4 \
    --data-root ${data_dir} \
    --print-interval 10 \
    --snapshot-interval 1000 \
    --device cuda \
    --mode train-all \
    --random-intrinsic 800 \
    --hsv-rand 0.2 \
    --use-stereo 2.2 \
    --fix_model_parts 'flow' 'feat' 'rot' \
    --result-dir ./train_multicamvo \
    --train-name ${train_name} \
    --debug-flag '' \
    --pose-model-name ./models/multicamvo_posenet_15000.pkl \
    --train-step ${step} \
    --trail-num 5 \
    --enable-pruning \
    --out-to-cml \
    # --not-write-log
    # --load-study \
    # --study-name multicamvo_B32_St100000_optuna_lr_dev3090_Feb_21_2023_01_13_55

##################################### End of Script ######################################
